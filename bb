# -*- coding: UTF-8 -*-

'''
==== install ====
> pip install beautifulsoup4
> pip3.7 install beautifulsoup4 (Python 3.7)
'''

'''
==== https://www.crummy.com/software/BeautifulSoup/bs4/doc/ ====
==== 1. parser ====
Python’s html.parser
    BeautifulSoup(html, 'html.parser')
**************************************
lxml’s HTML parser
    BeautifulSoup(html, "lxml")
lxml’s XML parser
    BeautifulSoup(xml, "lxml-xml")
    BeautifulSoup(xml, "xml")
**************************************
html5lib
    BeautifulSoup(html, "html5lib")

__建議使用 lxml，效能較好
> pip install lxml
> pip3.7 install lxml
'''
from bs4 import BeautifulSoup
import requests
import re

# ==============================================================================
HEADERS = {'User-Agent': 'Mozilla/5.0'}

def load_by_url(url):
    response = requests.get(url, headers=HEADERS)
    return BeautifulSoup(response.content, "lxml")

def load_by_html(html):
    return BeautifulSoup(html, "lxml")
# ==============================================================================

'''
  == 1.1. making the soup ==
  To parse a document, pass it into the BeautifulSoup constructor.
'''
html_doc = """
<html>
  <head>
    <title>The Dormouse's story</title>
  </head>
  <body>
    <p class="title">
      <b>The Dormouse's story</b>
    </p>
    <p class="story">Once upon a time there were three little sisters; and their names were
      <a href="http://example.com/elsie" class="sister" id="link1">Elsie</a>,
      <a href="http://example.com/lacie" class="sister" id="link2">Lacie</a> and
      <a href="http://example.com/tillie" class="sister" id="link3">Tillie</a>;
      and they lived at the bottom of a well.
    </p>
    <b id="comment1"><!-- story paragraph --></b>
    <p class="story story2">...</p>
  </body>
</html>
"""
soup = load_by_html(html_doc)
#print("========== html tree ==========")
##print(soup.prettify())
#print(soup.title)             # <title>The Dormouse's story</title>
#print(soup.title.name)        # title
#print(soup.title.string)      # The Dormouse's story
#print(soup.title.parent.name) # head
#print(soup.p)                 # <p class="title"><b>The Dormouse's story</b></p>
#print(soup.p['class'])        # ['title']
#print(soup.a)                 # <a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>
#print(soup.find_all('a'))     # [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>, <a ...>, <a ...>

'''
==== 2. kinds of objects ====
Beautiful Soup transforms a complex HTML document into a complex tree of Python objects.
But you’ll only ever have to deal with about four kinds of objects: Tag, NavigableString, BeautifulSoup, and Comment

  == 2.1. Tag ==
  A Tag object corresponds to an XML or HTML tag in the original document.
  Tags have a lot of attributes and methods, the most important features of a tag are its name and attributes.
  
    == Name==
    Every tag has a name, accessible as .name.
    __對 tag 可以用 .name 直接取得該 tag 的 name
    
    == Attributes ==
    A tag may have any number of attributes.
    You can access that dictionary directly as .attrs.
    You can access a tag’s attributes by treating the tag like a dictionary.
    __對 tag 可以用 .attrs 直接取得該 tag 的所有 attribute
    __對 tag 可以用像 dictionary 一樣直接取得某個 attribute 的值

  If you change a tag’s name, the change will be reflected in any HTML markup generated by Beautiful Soup.
  __改變 tag 的 name，則會跟著改變 Beautiful Soup 建立的 html
'''
#print("\n========== object - Tag ==========")
#tag_a_link3 = soup.find(id="link3")
#print(tag_a_link3)       # <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>
#print(type(tag_a_link3)) # <class 'bs4.element.Tag'>
#print(tag_a_link3.name)  # a
#print(tag_a_link3.attrs) # {'href': 'http://example.com/tillie', 'class': ['sister'], 'id': 'link3'}
#print(tag_a_link3['id']) # link3
#
#tag_a_link3.name = "p"
#print(tag_a_link3)       # <p class="sister" href="http://example.com/tillie" id="link3">Tillie</p>
'''
  == 2.2. NavigableString ==
  A NavigableString is just like a Python Unicode string, except that it also supports
    some of the features described in Navigating the tree and Searching the tree.
  
    == Comments ==
    The Comment object is just a special type of NavigableString.
    Beautiful Soup defines classes for anything else that might show up in an XML document:
      CData, ProcessingInstruction, Declaration, and Doctype, Just like Comment
    __上述 Comment, CData, ProcessingInstruction, Declaration, and Doctype 都是 NavigableString 的子類別
'''
#print("\n========== object - NavigableString ==========")
#tag_a_link1 = soup.find(id="link1")
#print(tag_a_link1)                 # <a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>
#print(tag_a_link1.string)          # Elsie
#print(type(tag_a_link1.string))    # <class 'bs4.element.NavigableString'>
#
#tag_b_comment1 = soup.find(id="comment1")
#print(tag_b_comment1.string)       #  story paragraph
#print(type(tag_b_comment1.string)) # <class 'bs4.element.Comment'>

'''
  == 2.3. BeautifulSoup ==
  The BeautifulSoup object itself represents the document as a whole.
  For most purposes, you can treat it as a Tag object.
  
  Since the BeautifulSoup object doesn’t correspond to an actual HTML or XML tag, it has no name and no attributes.
  But sometimes it’s useful to look at its .name, so it’s been given the special .name "[document]".
'''
#print("\n========== object - BeautifulSoup ==========")
#print(soup)       # <html><head>...</body></html>
#print(type(soup)) # <class 'bs4.BeautifulSoup'>
#print(soup.name)  # [document]

'''
==== 3. navigating the tree ====
  ******************************
  ps. 這裡的範例，parser 使用 lxml
  ******************************
  
  == 3.1. going down ==
    == 3.1.1. navigating using tag names ==
    The simplest way to navigate the parse tree is to say the name of the tag you want.
    Using a tag name as an attribute will give you only the first tag by that name
    __最簡單的方式為使用 tag 的 name，使用 tag name 走訪 tree 時，只會回傳符合該 name 的第一個 tag
    
    == 3.1.2. .contents and .children ==
    A tag’s children are available in a list called .contents
    A string does not have .contents, because it can’t contain anything
    __.contents 取得若為 NavigableString，則再用 .contents 會發生 AttributeError: 'NavigableString' object has no attribute 'contents'
    
    == 3.1.3. .descendants ==
    The .contents and .children attributes only consider a tag’s direct children.
    For instance, the <head> tag has a single direct child–the <title> tag.
    
    == 3.1.4. .string ==
    == 3.1.5. .strings and stripped_strings ==
'''
#print("\n==== Navigating the tree - tag name ====")
#print(soup.head)  # <head><title>The Dormouse's story</title></head>
#print(soup.title) # <title>The Dormouse's story</title>
#print(soup.a)     # <a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>
#### ps. 總共有 3 個 <a>，使用 tag name 只回傳第一個 tag

#print("\n==== Navigating the tree - .contents and .children ====")
#print(len(soup.contents))     # 2
#print(type(soup.contents))    # <class 'list'>
#print(soup.contents)          # [<html><head>...</body></html>, '\n'] (還有一個 '\n')

#tag_head = soup.head;
#print(type(tag_head))          # <class 'bs4.element.Tag'>
#print(tag_head.contents)       # ['\n', <title>The Dormouse's story</title>, '\n']
#
#tag_title = tag_head.contents[1]
#print(tag_title)               # <title>The Dormouse's story</title>
#print(type(tag_title))         # <class 'bs4.element.Tag'>
#print(tag_title.contents)      # ["The Dormouse's story"]
#
#val_title = tag_title.contents[0]
#print(val_title)               # The Dormouse's story
#print(type(val_title))         # <class 'bs4.element.NavigableString'>
##print(val_title.contents)     # AttributeError: 'NavigableString' object has no attribute 'contents'
#
#print(type(tag_head.children)) # <class 'list_iterator'>
#print(tag_head.children)       # <list_iterator object at 0x000000000xxxxxxx>
#for c in tag_head.children:
#    print(c)                   # <title>The Dormouse's story</title>
'''
  == 3.2. going up ==
    == 3.2.1. .parent ==
    access an element’s parent with the .parent attribute.
    
    == 3.2.2. .parents ==
    iterate over all of an element’s parents with .parents.
'''
#tag_title = soup.title
#print(tag_title)                #<title>The Dormouse's story</title>
#print(tag_title.parent)         #<head><title>The Dormouse's story</title></head>
#print(tag_title.string)         # The Dormouse's story
#print(tag_title.string.parent)  # <title>The Dormouse's story</title>

#tag_a_1st = soup.a
##print(tag_a_1st)               # <a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>
##print(type(tag_a_1st.parents)) # <class 'generator'>
#for p in tag_a_1st.parents:
#    if p is None:
#        print(p)
#    else:
#        print(p.name)
    # p
    # body
    # html
    # [document]
    #### ps. 官網有第五筆 None，不知為何這裡只印出四筆
    
'''
  == 3.3. going sideways ==
    == 3.3.1. .next_sibling and .previous_sibling ==
    use .next_sibling and .previous_sibling to navigate between page elements that are on the same level of the parse tree
    __走訪同一層的兄弟 element
    
    == 3.3.2. .next_siblings and .previous_siblings ==
'''
#tag_a1st = soup.a
#print(tag_a1st)                  # <a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>
#print(tag_a1st.next_sibling)     # ,
#print(tag_a1st.previous_sibling) # Once upon a time there were three little sisters; and their names were
##### 為什麼 next_sibling 和 previous_sibling 的值不是 <tag> !!
#print(tag_a1st.next_sibling.next_sibling) # <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>
#print(tag_a1st.previous_sibling.previous_sibling) # None

'''
  == 3.4. going back and forth ==
    == 3.4.1. .next_element and .previous_element ==
    == 3.4.2. .next_elements and .previous_elements ==
'''
#tag_a1st = soup.a
#print(tag_a1st)              # <a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>
#print(tag_a1st.next_element) # Elsie
#print(tag_a1st.next_sibling) # ,

'''
==== 4. searching the tree ====
  == 4.1. kinds of filters ==
  Beautiful Soup defines a lot of methods for searching the parse tree, the two most popular methods: find() and find_all().
  By passing in a filter to an argument like find_all()
'''
#### a string
#print(soup.find_all('b'))       # [<b>The Dormouse's story</b>, <b id="comment1"><!-- story paragraph --></b>]

#### a regular expression
#for tag in soup.find_all(re.compile("^b")):
#    print(tag.name)
#    # body
#    # b
#    # b

#### a list
#print(soup.find_all(["a", "b"])) # [<b>The Dormouse's story</b>, <a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>, <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>, <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>, <b id="comment1"><!-- story paragraph --></b>]

#### a function
#def has_class_but_no_id(tag):
#    return tag.has_attr('id') and not tag.has_attr('class')

#print(soup.find_all(has_class_but_no_id)) # [<b id="comment1"><!-- story paragraph --></b>]

'''  
  == 4.2. search methods ==
    == 4.2.1. find_all() ==
    find_all(name, attrs, recursive, string, limit, **kwargs)
    
      == recursive ==
      If you only want Beautiful Soup to consider direct children, you can pass in recursive=False.
      __預設或是 recursive=True，會遞迴的走訪符合的 tag
'''
#### == name ==
#print(soup.find_all(id='link2')) # [<a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>]

#print(soup.find_all(id=True))
# [ <a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>, 
#   <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>,
#   <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>,
#   <b id="comment1"><!-- story paragraph --></b> ]

#### == attrs ==
#print(soup.find_all(attrs={"class": "sister"})) # [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>, <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>, <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]

#### == recursive ==
#print(soup.find_all("title"))                  # [<title>The Dormouse's story</title>]
#print(soup.find_all("title", recursive=True))  # [<title>The Dormouse's story</title>]
#print(soup.find_all("title", recursive=False)) # []

#### == string ==
#print(soup.find_all("a", string="Elsie"))      # [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>]
#print(soup.find_all("a", text="Elsie"))        # [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>]
##### ps. The string argument is new in Beautiful Soup 4.4.0. In earlier versions it was called text

#### == limit ==
#print(soup.find_all("a"))                      # [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>, <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>, <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]
#print(soup.find_all("a", limit=2))             # [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>, <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>]

'''    
    == 4.2.2. find() ==
    find(name, attrs, recursive, string, **kwargs)
    
    == 4.2.3. find_parents() and find_parent() ==
    find_parents(name, attrs, string, limit, **kwargs)
    find_parent(name, attrs, string, **kwargs)
    
    == 4.2.4. find_next_siblings() and find_next_sibling() ==
    find_next_siblings(name, attrs, string, limit, **kwargs)
    find_next_sibling(name, attrs, string, **kwargs)
    
    == 4.2.5. find_previous_siblings() and find_previous_sibling() ==
    find_previous_siblings(name, attrs, string, limit, **kwargs)
    find_previous_sibling(name, attrs, string, **kwargs)
    
    == 4.2.6 find_all_next() and find_next() ==
    find_all_next(name, attrs, string, limit, **kwargs)
    find_next(name, attrs, string, **kwargs)
    
    == 4.2.7. find_all_previous() and find_previous() ==
    find_all_previous(name, attrs, string, limit, **kwargs)
    find_previous(name, attrs, string, **kwargs)
'''

'''
  == 4.3. CSS selectors ==
  As of version 4.7.0, Beautiful Soup supports most CSS4 selectors via the SoupSieve project.
  BeautifulSoup has a .select() method which uses SoupSieve to run a CSS selector against a parsed document and return all the matching elements.
'''
#print(soup.find_all('p', class_='title')) # [<p class="title"><b>The Dormouse's story</b></p>]

#print(soup.find_all('p', class_='story story2')) # [<p class="story story2">...</p>]
#print(soup.find_all('p', class_='story2 story')) # []

'''
==== 5. modifying the tree ====
'''

'''
==== 6. output ====
'''
